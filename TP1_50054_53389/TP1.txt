Attention:
- Do not edit this file in text editors like Word. Use a plain text editor only. If in doubt you can use Spyder as a text editor.
- Do not change the structure of this file. Just fill in your answers in the places provided (After the R#: tag).
- You can add lines in the spaces for your answers but your answers should be brief and straight to the point.

Atenção:
- Não edite este ficheiro em programas como Word e afins. Use exclusivamente um editor de texto simples. Em caso de dúvida, use o editor do Spyder.
- Não altere a estrutura deste ficheiro. Preencha as respostas apenas nos espaços respectivos (a seguir à tag R#:)
- Pode adicionar linhas no espaço para as respostas mas as respostas devem ser sucintas e directas.

Linking images and reports/Incluir imagens e relatórios
- You can link a .png or .html file in your answers by typing the name of the file in a separate line. The file must be in the same folder as this TP1.txt file. See the examples below:
- Pode ligar às respostas um ficheiro .png ou .html escrevendo o nome do ficheiro numa linha separada. O ficheiro tem de estar presente na mesma pasta em que está este ficheiro TP1.txt. Por exemplo:

exemplo.png
exemplo.html

PERGUNTAS/QUESTIONS:

Q1: Explain the architecture of your best model for the multiclass classification problem, including a description and justification of the output activation and loss functions. Also justify your choice of layers and activation functions for the hidden layers.
Q1; Explique a arquitectura do seu melhor modelo para o problema de classificação de multi-classe, incluindo uma descrição e justificação das funções de activação à saída da rede e função de custo. Justifique também a sua escolha de camadas e de funções de activação para as camadas escondidas.
R1: O nosso modelo de classificação multi-classe começa com uma input layer de shape (64,64,3) equivalente ao formato da imagem, seguida de uma convolutional layer com 32 filtros e kernel size de 1x1, de um BatchNormalization para normalizar o input e um MaxPooling para reduzir o output da camada anterior. Segue-se uma repetição das três operações anteriores com o aumento do kernel size da convolutional layer para 3x3 e uma última combinação de convolutional layer e MaxPooling. Para finalizar as hidden layers utilizamos uma camada densa com dimensão de 32 seguida de um BatchNormalization e um Dropout de 0.25, ignorando 25% dos neurónios. Por fim, a output layer consiste numa camada densa com dimensão de 10, correspondente às probabilidades de pertença aos 10 tipos de pokemon. 
Funções de Ativação:
Hidden Layers – ReLu – A função ReLu é a função mais usada em camadas escondidas pois reduz a probabilidade de ocorrências de vanishing gradient. Como devolve o valor 0 para inputs negativos, a função ReLu reduz também o número de ativações de neurónios na rede.
Output Layer – Softmax – A função softmax é a função mais adequada para problemas de classificação de multi-classe pois devolve um vetor de soma 1, que corresponde à probabilidade de pertença a uma das classes (neste caso, a probabilidade de um pokemon ser de determinado tipo).
Função de Custo:
Categorical Cross-entropy – A função categorical_crossentropy é a função de custo mais comum em problemas de classificação de multi-classe e esta função calcula a diferença entre as distribuições de probabilidade das categorias.


Q2: Discuss and explain how you selected the best model for the multiclass classifcation problem, showing the relevant plots, comparing the different models you tried and evaluating the results you obtained.
Q2: Discuta e explique como seleccionou o melhor modelo para o problema de classificação multi-classe, mostrando os gráficos relevantes, comparando os diferentes modelos que experimentou e avaliando os resultados obtidos.
R2: Na procura do melhor modelo possível para este problema de classificação multi-classe fizemos várias experiências e comparámos os resultados obtidos na precisão e custo do treino e validação.
Testámos três optimizadores: SDG, Adam e RMSprop. Para o Adam, decidímos optar por uma variante conhecida como Amsgrad, apresentada por Sashank J. Reddi, Satyen Kale, e Sanjiv Kumar no paper "On the convergence of Adam and beyond".
Como se pode ver na imagem SDGvsAdamvsRMSprop, o optimizador Adam apresentou uma performance muito superior atingindo valores mais altos de precisão e sendo extremamente mais rápido.
No que diz respeito ao rate de Dropout, a imagem Dropout0.2vs0.25vs0.3 mostra os resultados obtidos ao usar este modelo com rates de 0.2, 0.25 e 0.3. Optámos por utilizar um valor de 0.25 mas um dropout rate de 0.2 também seria aceitável.
Experimentámos também aumentar o número de camadas de convolução e variar o número dos seus filtros 64 para 32 mas as diferenças nos resultados foram insignificantes.
O learning rate foi testado com valores de 0.001, 0.002, 0.003, 0.004, 0.005 e 0.01 e os resultados estão disponíveis na imagem LearningRate0.001vs0.002vs0.003vs0.004vs0.005vs0.01. 0.01 foi o rate escolhido.
Também decidimos variar o tamanho da penúltima camada densa (não de output) de 64 para 32 e verificar qual o melhor valor para o problema. Os resultados (multic_densesize.png), mostram que acabam quase no mesmo tempo (1s de diferença), porém, com 32, há um maior pico na accuracy de validação (99.5%), pelo que foi por este valor que optámos na nossa rede.

SDGvsAdamvsRMSprop.png
Dropout0.2vs0.25vs0.3.png
multic_densesize.png
LearningRate0.001vs0.002vs0.003vs0.004vs0.005vs0.01.png


Q3: For the multilabel classification problem, explain how you adpated your previous model, what experiments you did to optimize the architecture and discuss your results. Do not forget to explain your choice of activation and loss functions and why this model differs from the previous one.
Q3: Para o problema de classificação com múltiplas etiquetas, explique como adaptou o modelo anterior, que experiências fez para optimizar a arquitectura e discuta os resultados. Não se esqueça de explicar a escolha de funções de activação e custo e porque é que este modelo difere do anterior.
R3: O nosso modelo de classificação multi-label é semelhante ao que apresentámos para o problema de classificação multi-classe com alterações às funções de ativação e de custo.
Funções de Ativação:
Hidden Layers – ReLu – Pelas mesmas razões referidas na questão 1, continuamos a usar a função ReLu nas camadas escondidas.
Output Layer – Sigmoid – A função sigmoid devolve a probabilidade de pertença a cada uma das classes (entre 0 e 1). Sendo essas probabilidades independentes, esta função permite que um exemplo seja atribuído a várias classes.
Função de Custo:
Binary Cross-entropy – A função binary_crossentropy é a mais adequada para problemas de classificação de multi-label pois trata também as distribuições de probabilidade de diferentes categorias de forma independente.


Q4: Explain the architecture of your best model for the semantic segmentation problem, including a description and justification of the output activation and loss functions. Also justify your choice of layers and activation functions for the hidden layers.
Q4: Explique a arquitectura do seu melhor modelo para o problema de segmentação semântica, incluindo uma descrição e justificação das funções de activação à saída da rede e função de custo. Justifique também a sua escolha de camadas e de funções de activação para as camadas escondidas.
R4: A arquitetura usada para segmentação semântica, em relação ao problema de multiclass, reparámos que a rede, sem uma penúltima camada densa, seguida de batchnormalization, e um dropout, a rede se comportava melhor. Assim, essa é a primeira grande diferença em relação ao modelo de multiclass.
Como, neste problema queríamos analisar a image pixel a pixel, e concluir se o pixel pertence ao pokémon ou não, também alterámos a dimensão da última layer densa (e única) para 4096=64*64, de forma a analisar todos os pixeis da imagem.
Como o problema de segmentação semântica pode ser visto como um problema de classificação binária (o pixel ou pertence ao pokémon, ou não pertence), optámos por escolher a binary crossentropy loss function e binary accuracy.
Ainda dentro da arquitetura da nossa rede, as hidden layers têm como função de ativação a ReLU (Rectified Linear Units) para colmatar o problema dos vanishing gradients, pois retorna 0, sempre que xi<0 e xi quando xi>0, impedindo assim que a derivada da função dê 0, e impessa a rede de continuar a treinar os pesos.
Na função de ativação final, optámos por sigmoid pois ser a mais indicada para problemas de classificação binária (ainda assim testámos com softmax).


Q5: Discuss and explain how you selected the best model for the semantic segmentation problem, showing the relevant plots, comparing the different models you tried and evaluating the results you obtained. Use the auxiliary functions provided to show the correspondence between your predicted segmentation masks and the masks provided in the test set.
Q5: Discuta e explique como seleccionou o melhor modelo para o problema de segmentação semântica, mostrando os gráficos relevantes, comparando os diferentes modelos que experimentou e avaliando os resultados obtidos. Use as funções auxiliares fornecidas para mostrar a correspondência entre as máscaras de segmentação previstas e as máscaras no conjunto de teste.
R5: Para encontrar e selecionar o melhor modelo para o problema em questão, começámos por validar, até mais ou menos quantas epochs é que seria necessário correr, com o Batch_Size = 10, até a accuracy começar a estabilizar, ou atingir um dos seus picos. Assim, corremos até à epoch 30, e reparámos que não valeria muito a pena correr para lá de 10 epochs (seg_epochsval.png). Assim, todos os testes efetuados para este problema, foram de batch_size = 10 = n_epochs. 
O segundo teste que corremos, foi para avaliar o comportamento e accuracy da rede com uma camada densa antes da camada de output, seguida de um batchnormalization e um dropout, e concluímos que, sem esta, a rede alcançava melhor resultados de accuracy, e em menos tempo (seg_dense_or_nodense.png).
De seguida, decidímos averiguar qual o melhor tamanho dos filtros das camadas de convolução (32 vs 64), no final, concluímos que com 32, a rede alcançava melhor accuracy, e em menor tempo de treino (seg_convsize.png).
Apesar de sabermos que, para problemas de classificação binária, é melhor utilizar, como função de ativação final sigmoid ao invés de softmax, decídimos realizar o teste, de forma a obter certezas. Realmente, comprova-se que para problemas de classificação binária, é melhor usar a função de ativação sigmoid. (seg_lastactivfunc.png)
Falando de otimizadores, decidímos voltar a comparar o Adam com amsgrad, com o SGD e RMSprop para este problema. Concluímos assim que não há muito diferença entre qual usar pois os valores de accuracy são todos bastante semelhantes, e o tempo de treino também, à exceção do RMSprop. Assim, optámos por deixar o Adam, uma vez que não há grande diferença entre ele e o SGD. Excluímos logo o RMSprop, pois era o que demorava mais tempo a treinar. (seg_opt.png)
Por fim, sendo que o learning rate default do Adam é 0.001, decidímos testar o comportamento do mesmo com learning rates de 0.001, 0.002, 0.003, 0.004, 0.005, e 0.01, para observar com um learning rate bastante mais elevado. Após observar o resultado, decidímos manter o otimizador com learning rate = 0.001, pois é o lr que alcançou melhores resultados de accuracy (cerca de 97,2%). (seg_lr.png).
No final, é possível ver o comportamento final da nossa rede. Na figura seg_finalnet.png, é possível ver a binary val accuracy ao longo dos vários epochs do nosso processo de treino. A nossa arquitetura final, consegue então alcançar um pico de accuracy de cerca de 97,5% em cerca de 22 segundos. Na figura ovarlay_masks.png podemos ver a aplicação da nossa máscara às imagens dos pókemons, onde tenta delinear os pixeis pertencentes aos pokemons, dividindo-os do fundo da imagem.
Na imagem compare_masks.png, é possível comparar a nossa máscara com a verdadeira máscara, onde os pontos brancos representam pixeis que pertencem a ambas as máscaras, pontos vermelhos pertencem à nossa máscara mas não à verdadeira máscara, e pontos verdes pertencem à verdadeira, e não à nossa. Pontos pretos, representam pixeis que não pertencem a nenhuma máscara (são de facto fundo).

seg_epochsval.png
seg_dense_or_nodense.png
seg_convsize.png
seg_lastactivfunc.png
seg_opt.png
seg_lr.png
seg_finalnet.png
ovarlay_masks.png
compare_masks.png


Q6: (Optional) Discuss the impact on training and overfitting for the two classification problems when using available networks pretrained on ImageNet (e.g. EfficientNetB0, MobileNetV2 or others). Explain how you used these networks and discuss the effect they had relative to your models.
Q6: (Opcional) Discuta o impacto no treino e sobreajustamento nos dois problemas de classificação se usar redes pré-treinadas no dataset ImageNet (e.g. EfficientNetB0, MobileNetV2 or others). Explique como usou estas redes e discuta o efeito que tiveram nos seus modelos.
R6: Começámos por importar a rede EfficientNetB0 providenciando a input shape (64,64,3) equivalente ao formato da imagem. A esta rede adicionámos as camadas densas que usámos nos nossos modelos multi-classe e multi-label referidos anteriormente. Os resultados obtidos podem ser observados nas imagens EfficientNetB0_MultiClass e EfficientNetB0_MultiLabel.
Como era previsível por se tratar de uma rede pré-treinada, estes resultados ficam aquém dos obtidos nos nossos modelos. Além disso, no modelo multi-classe pode ser observado um claro caso de overfitting pois os valores de precisão em treino e validação não convergem (embora os valores de treino ultrapassem 70%, os valores de validação não sobem acima dos 55%).

EfficientNetB0_MultiClass.png
EfficientNetB0_MultiLabel.png